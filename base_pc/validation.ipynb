{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91fb317-758b-4fb5-ac36-112646726f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^CFound existing installation: onnxruntime 1.22.0\n",
      "Uninstalling onnxruntime-1.22.0:\n",
      "  Would remove:\n",
      "    c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages\\onnxruntime-1.22.0.dist-info\\*\n",
      "    c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages\\onnxruntime\\*\n",
      "    c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\scripts\\onnxruntime_test.exe\n",
      "  Would not remove (might be manually added):\n",
      "    c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_providers_cuda.dll\n",
      "    c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_providers_tensorrt.dll\n",
      "Proceed (Y/n)? \n",
      "\n",
      "Requirement already satisfied: onnxruntime-gpu in c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages (1.22.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages (from onnxruntime-gpu) (25.2.10)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages (from onnxruntime-gpu) (2.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages (from onnxruntime-gpu) (24.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages (from onnxruntime-gpu) (5.29.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages (from onnxruntime-gpu) (1.13.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime-gpu) (3.5.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\usudl\\anaconda3\\envs\\yolov-env\\lib\\site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall onnxruntime\n",
    "!pip install onnxruntime-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d3ace-9909-43d8-8e82-c25fd632f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-keras\n",
    "!pip install sng4onnx==1.0.1\n",
    "!pip install onnx_graphsurgeon==0.3.26\n",
    "!pip install ai-edge-litert==1.2.0\n",
    "!pip install onnx2tf==1.26.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a11c047-f192-4d0e-80ff-9941d1295547",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo benchmark model=../trained_models/yolo11n-obb-320.pt data='../datasets/obb_mini_things-3/data.yaml' imgsz=320 device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15df818-e098-4639-b04f-51eacff03785",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openvino-dev[onnx] openvino\n",
    "!pip install onnx onnxruntime-gpu  # gunakan onnxruntime-gpu jika pakai CUDA\n",
    "!pip install PyMNN-*-cp310-cp310-linux_x86_64.whl  # sesuai Python & OS kamu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98632cbf-e3ff-409c-99df-97a602a62ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Mengonversi yolo11n-obb-320.pt...\n",
      "   🔁 Export ke format: onnx\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.3s, saved as '..\\trained_models\\yolo11n-obb-320.onnx' (10.3 MB)\n",
      "\n",
      "Export complete (3.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-320.onnx imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-320.onnx imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: openvino\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.2.0-19140-c01cd93e24d-releases/2025/2...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  3.3s, saved as '..\\trained_models\\yolo11n-obb-320_openvino_model\\' (10.6 MB)\n",
      "\n",
      "Export complete (4.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-320_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-320_openvino_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: mnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.2s, saved as '..\\trained_models\\yolo11n-obb-320.onnx' (10.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.1...\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m export success  4.1s, saved as '..\\trained_models\\yolo11n-obb-320.mnn' (10.3 MB)\n",
      "\n",
      "Export complete (4.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-320.mnn imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-320.mnn imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: ncnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.7s, saved as '..\\trained_models\\yolo11n-obb-320.torchscript' (10.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250503...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running 'C:\\Users\\usudl\\anaconda3\\envs\\yolov-env\\Lib\\site-packages\\ultralytics\\pnnx.exe ..\\trained_models\\yolo11n-obb-320.torchscript ncnnparam=..\\trained_models\\yolo11n-obb-320_ncnn_model\\model.ncnn.param ncnnbin=..\\trained_models\\yolo11n-obb-320_ncnn_model\\model.ncnn.bin ncnnpy=..\\trained_models\\yolo11n-obb-320_ncnn_model\\model_ncnn.py pnnxparam=..\\trained_models\\yolo11n-obb-320_ncnn_model\\model.pnnx.param pnnxbin=..\\trained_models\\yolo11n-obb-320_ncnn_model\\model.pnnx.bin pnnxpy=..\\trained_models\\yolo11n-obb-320_ncnn_model\\model_pnnx.py pnnxonnx=..\\trained_models\\yolo11n-obb-320_ncnn_model\\model.pnnx.onnx fp16=0 device=cuda inputshape=\"[1, 3, 640, 640]\"'\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success  1.3s, saved as '..\\trained_models\\yolo11n-obb-320_ncnn_model' (10.3 MB)\n",
      "\n",
      "Export complete (3.6s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-320_ncnn_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-320_ncnn_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "\n",
      "🚀 Mengonversi yolo11n-obb-640.pt...\n",
      "   🔁 Export ke format: onnx\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.2s, saved as '..\\trained_models\\yolo11n-obb-640.onnx' (10.3 MB)\n",
      "\n",
      "Export complete (1.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-640.onnx imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-640.onnx imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: openvino\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.2.0-19140-c01cd93e24d-releases/2025/2...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  2.5s, saved as '..\\trained_models\\yolo11n-obb-640_openvino_model\\' (10.6 MB)\n",
      "\n",
      "Export complete (2.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-640_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-640_openvino_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: mnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.0s, saved as '..\\trained_models\\yolo11n-obb-640.onnx' (10.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.1...\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m export success  2.2s, saved as '..\\trained_models\\yolo11n-obb-640.mnn' (10.3 MB)\n",
      "\n",
      "Export complete (3.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-640.mnn imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-640.mnn imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: ncnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.9s, saved as '..\\trained_models\\yolo11n-obb-640.torchscript' (10.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250503...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running 'C:\\Users\\usudl\\anaconda3\\envs\\yolov-env\\Lib\\site-packages\\ultralytics\\pnnx.exe ..\\trained_models\\yolo11n-obb-640.torchscript ncnnparam=..\\trained_models\\yolo11n-obb-640_ncnn_model\\model.ncnn.param ncnnbin=..\\trained_models\\yolo11n-obb-640_ncnn_model\\model.ncnn.bin ncnnpy=..\\trained_models\\yolo11n-obb-640_ncnn_model\\model_ncnn.py pnnxparam=..\\trained_models\\yolo11n-obb-640_ncnn_model\\model.pnnx.param pnnxbin=..\\trained_models\\yolo11n-obb-640_ncnn_model\\model.pnnx.bin pnnxpy=..\\trained_models\\yolo11n-obb-640_ncnn_model\\model_pnnx.py pnnxonnx=..\\trained_models\\yolo11n-obb-640_ncnn_model\\model.pnnx.onnx fp16=0 device=cuda inputshape=\"[1, 3, 640, 640]\"'\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success  1.2s, saved as '..\\trained_models\\yolo11n-obb-640_ncnn_model' (10.3 MB)\n",
      "\n",
      "Export complete (3.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-640_ncnn_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-640_ncnn_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "\n",
      "🚀 Mengonversi yolo11n-obb-1280.pt...\n",
      "   🔁 Export ke format: onnx\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.7s, saved as '..\\trained_models\\yolo11n-obb-1280.onnx' (10.3 MB)\n",
      "\n",
      "Export complete (2.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-1280.onnx imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-1280.onnx imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: openvino\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.2.0-19140-c01cd93e24d-releases/2025/2...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  2.9s, saved as '..\\trained_models\\yolo11n-obb-1280_openvino_model\\' (10.6 MB)\n",
      "\n",
      "Export complete (3.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-1280_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-1280_openvino_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: mnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.2s, saved as '..\\trained_models\\yolo11n-obb-1280.onnx' (10.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.1...\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m export success  1.4s, saved as '..\\trained_models\\yolo11n-obb-1280.mnn' (10.3 MB)\n",
      "\n",
      "Export complete (2.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-1280.mnn imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-1280.mnn imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: ncnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11n-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (5.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.7s, saved as '..\\trained_models\\yolo11n-obb-1280.torchscript' (10.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250503...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running 'C:\\Users\\usudl\\anaconda3\\envs\\yolov-env\\Lib\\site-packages\\ultralytics\\pnnx.exe ..\\trained_models\\yolo11n-obb-1280.torchscript ncnnparam=..\\trained_models\\yolo11n-obb-1280_ncnn_model\\model.ncnn.param ncnnbin=..\\trained_models\\yolo11n-obb-1280_ncnn_model\\model.ncnn.bin ncnnpy=..\\trained_models\\yolo11n-obb-1280_ncnn_model\\model_ncnn.py pnnxparam=..\\trained_models\\yolo11n-obb-1280_ncnn_model\\model.pnnx.param pnnxbin=..\\trained_models\\yolo11n-obb-1280_ncnn_model\\model.pnnx.bin pnnxpy=..\\trained_models\\yolo11n-obb-1280_ncnn_model\\model_pnnx.py pnnxonnx=..\\trained_models\\yolo11n-obb-1280_ncnn_model\\model.pnnx.onnx fp16=0 device=cuda inputshape=\"[1, 3, 640, 640]\"'\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success  1.1s, saved as '..\\trained_models\\yolo11n-obb-1280_ncnn_model' (10.3 MB)\n",
      "\n",
      "Export complete (3.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11n-obb-1280_ncnn_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11n-obb-1280_ncnn_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "\n",
      "🚀 Mengonversi yolo11s-obb-320.pt...\n",
      "   🔁 Export ke format: onnx\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (18.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.5s, saved as '..\\trained_models\\yolo11s-obb-320.onnx' (37.2 MB)\n",
      "\n",
      "Export complete (2.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-320.onnx imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-320.onnx imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: openvino\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (18.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.2.0-19140-c01cd93e24d-releases/2025/2...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  2.6s, saved as '..\\trained_models\\yolo11s-obb-320_openvino_model\\' (37.5 MB)\n",
      "\n",
      "Export complete (2.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-320_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-320_openvino_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: mnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (18.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.6s, saved as '..\\trained_models\\yolo11s-obb-320.onnx' (37.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.1...\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m export success  2.3s, saved as '..\\trained_models\\yolo11s-obb-320.mnn' (37.2 MB)\n",
      "\n",
      "Export complete (3.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-320.mnn imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-320.mnn imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: ncnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (18.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.7s, saved as '..\\trained_models\\yolo11s-obb-320.torchscript' (37.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250503...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running 'C:\\Users\\usudl\\anaconda3\\envs\\yolov-env\\Lib\\site-packages\\ultralytics\\pnnx.exe ..\\trained_models\\yolo11s-obb-320.torchscript ncnnparam=..\\trained_models\\yolo11s-obb-320_ncnn_model\\model.ncnn.param ncnnbin=..\\trained_models\\yolo11s-obb-320_ncnn_model\\model.ncnn.bin ncnnpy=..\\trained_models\\yolo11s-obb-320_ncnn_model\\model_ncnn.py pnnxparam=..\\trained_models\\yolo11s-obb-320_ncnn_model\\model.pnnx.param pnnxbin=..\\trained_models\\yolo11s-obb-320_ncnn_model\\model.pnnx.bin pnnxpy=..\\trained_models\\yolo11s-obb-320_ncnn_model\\model_pnnx.py pnnxonnx=..\\trained_models\\yolo11s-obb-320_ncnn_model\\model.pnnx.onnx fp16=0 device=cuda inputshape=\"[1, 3, 640, 640]\"'\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success  1.9s, saved as '..\\trained_models\\yolo11s-obb-320_ncnn_model' (37.2 MB)\n",
      "\n",
      "Export complete (3.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-320_ncnn_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-320_ncnn_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "\n",
      "🚀 Mengonversi yolo11s-obb-640.pt...\n",
      "   🔁 Export ke format: onnx\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (18.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.2s, saved as '..\\trained_models\\yolo11s-obb-640.onnx' (37.2 MB)\n",
      "\n",
      "Export complete (2.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-640.onnx imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-640.onnx imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: openvino\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (18.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.2.0-19140-c01cd93e24d-releases/2025/2...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  2.4s, saved as '..\\trained_models\\yolo11s-obb-640_openvino_model\\' (37.5 MB)\n",
      "\n",
      "Export complete (3.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-640_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-640_openvino_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: mnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (18.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.6s, saved as '..\\trained_models\\yolo11s-obb-640.onnx' (37.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.1...\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m export success  3.3s, saved as '..\\trained_models\\yolo11s-obb-640.mnn' (37.2 MB)\n",
      "\n",
      "Export complete (3.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-640.mnn imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-640.mnn imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: ncnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (18.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.6s, saved as '..\\trained_models\\yolo11s-obb-640.torchscript' (37.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250503...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running 'C:\\Users\\usudl\\anaconda3\\envs\\yolov-env\\Lib\\site-packages\\ultralytics\\pnnx.exe ..\\trained_models\\yolo11s-obb-640.torchscript ncnnparam=..\\trained_models\\yolo11s-obb-640_ncnn_model\\model.ncnn.param ncnnbin=..\\trained_models\\yolo11s-obb-640_ncnn_model\\model.ncnn.bin ncnnpy=..\\trained_models\\yolo11s-obb-640_ncnn_model\\model_ncnn.py pnnxparam=..\\trained_models\\yolo11s-obb-640_ncnn_model\\model.pnnx.param pnnxbin=..\\trained_models\\yolo11s-obb-640_ncnn_model\\model.pnnx.bin pnnxpy=..\\trained_models\\yolo11s-obb-640_ncnn_model\\model_pnnx.py pnnxonnx=..\\trained_models\\yolo11s-obb-640_ncnn_model\\model.pnnx.onnx fp16=0 device=cuda inputshape=\"[1, 3, 640, 640]\"'\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success  1.9s, saved as '..\\trained_models\\yolo11s-obb-640_ncnn_model' (37.2 MB)\n",
      "\n",
      "Export complete (4.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-640_ncnn_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-640_ncnn_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "\n",
      "🚀 Mengonversi yolo11s-obb-1280.pt...\n",
      "   🔁 Export ke format: onnx\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (19.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.4s, saved as '..\\trained_models\\yolo11s-obb-1280.onnx' (37.2 MB)\n",
      "\n",
      "Export complete (2.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-1280.onnx imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-1280.onnx imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: openvino\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (19.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.2.0-19140-c01cd93e24d-releases/2025/2...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  2.6s, saved as '..\\trained_models\\yolo11s-obb-1280_openvino_model\\' (37.5 MB)\n",
      "\n",
      "Export complete (3.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-1280_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-1280_openvino_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: mnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (19.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.3s, saved as '..\\trained_models\\yolo11s-obb-1280.onnx' (37.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.1...\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m export success  2.9s, saved as '..\\trained_models\\yolo11s-obb-1280.mnn' (37.2 MB)\n",
      "\n",
      "Export complete (3.6s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-1280.mnn imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-1280.mnn imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: ncnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11s-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (19.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  1.7s, saved as '..\\trained_models\\yolo11s-obb-1280.torchscript' (37.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250503...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running 'C:\\Users\\usudl\\anaconda3\\envs\\yolov-env\\Lib\\site-packages\\ultralytics\\pnnx.exe ..\\trained_models\\yolo11s-obb-1280.torchscript ncnnparam=..\\trained_models\\yolo11s-obb-1280_ncnn_model\\model.ncnn.param ncnnbin=..\\trained_models\\yolo11s-obb-1280_ncnn_model\\model.ncnn.bin ncnnpy=..\\trained_models\\yolo11s-obb-1280_ncnn_model\\model_ncnn.py pnnxparam=..\\trained_models\\yolo11s-obb-1280_ncnn_model\\model.pnnx.param pnnxbin=..\\trained_models\\yolo11s-obb-1280_ncnn_model\\model.pnnx.bin pnnxpy=..\\trained_models\\yolo11s-obb-1280_ncnn_model\\model_pnnx.py pnnxonnx=..\\trained_models\\yolo11s-obb-1280_ncnn_model\\model.pnnx.onnx fp16=0 device=cuda inputshape=\"[1, 3, 640, 640]\"'\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success  1.9s, saved as '..\\trained_models\\yolo11s-obb-1280_ncnn_model' (37.2 MB)\n",
      "\n",
      "Export complete (4.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11s-obb-1280_ncnn_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11s-obb-1280_ncnn_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "\n",
      "🚀 Mengonversi yolo11m-obb-320.pt...\n",
      "   🔁 Export ke format: onnx\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.5s, saved as '..\\trained_models\\yolo11m-obb-320.onnx' (80.0 MB)\n",
      "\n",
      "Export complete (3.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-320.onnx imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-320.onnx imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: openvino\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.2.0-19140-c01cd93e24d-releases/2025/2...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  4.0s, saved as '..\\trained_models\\yolo11m-obb-320_openvino_model\\' (80.3 MB)\n",
      "\n",
      "Export complete (4.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-320_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-320_openvino_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: mnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.5s, saved as '..\\trained_models\\yolo11m-obb-320.onnx' (80.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.1...\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m export success  4.0s, saved as '..\\trained_models\\yolo11m-obb-320.mnn' (79.9 MB)\n",
      "\n",
      "Export complete (5.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-320.mnn imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-320.mnn imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: ncnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-320.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  2.5s, saved as '..\\trained_models\\yolo11m-obb-320.torchscript' (80.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250503...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running 'C:\\Users\\usudl\\anaconda3\\envs\\yolov-env\\Lib\\site-packages\\ultralytics\\pnnx.exe ..\\trained_models\\yolo11m-obb-320.torchscript ncnnparam=..\\trained_models\\yolo11m-obb-320_ncnn_model\\model.ncnn.param ncnnbin=..\\trained_models\\yolo11m-obb-320_ncnn_model\\model.ncnn.bin ncnnpy=..\\trained_models\\yolo11m-obb-320_ncnn_model\\model_ncnn.py pnnxparam=..\\trained_models\\yolo11m-obb-320_ncnn_model\\model.pnnx.param pnnxbin=..\\trained_models\\yolo11m-obb-320_ncnn_model\\model.pnnx.bin pnnxpy=..\\trained_models\\yolo11m-obb-320_ncnn_model\\model_pnnx.py pnnxonnx=..\\trained_models\\yolo11m-obb-320_ncnn_model\\model.pnnx.onnx fp16=0 device=cuda inputshape=\"[1, 3, 640, 640]\"'\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success  4.2s, saved as '..\\trained_models\\yolo11m-obb-320_ncnn_model' (79.9 MB)\n",
      "\n",
      "Export complete (7.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-320_ncnn_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-320_ncnn_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "\n",
      "🚀 Mengonversi yolo11m-obb-640.pt...\n",
      "   🔁 Export ke format: onnx\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.5s, saved as '..\\trained_models\\yolo11m-obb-640.onnx' (80.0 MB)\n",
      "\n",
      "Export complete (3.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-640.onnx imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-640.onnx imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: openvino\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.2.0-19140-c01cd93e24d-releases/2025/2...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  3.9s, saved as '..\\trained_models\\yolo11m-obb-640_openvino_model\\' (80.3 MB)\n",
      "\n",
      "Export complete (4.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-640_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-640_openvino_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: mnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.4s, saved as '..\\trained_models\\yolo11m-obb-640.onnx' (80.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.1...\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m export success  3.9s, saved as '..\\trained_models\\yolo11m-obb-640.mnn' (79.9 MB)\n",
      "\n",
      "Export complete (4.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-640.mnn imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-640.mnn imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: ncnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-640.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  2.3s, saved as '..\\trained_models\\yolo11m-obb-640.torchscript' (80.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250503...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running 'C:\\Users\\usudl\\anaconda3\\envs\\yolov-env\\Lib\\site-packages\\ultralytics\\pnnx.exe ..\\trained_models\\yolo11m-obb-640.torchscript ncnnparam=..\\trained_models\\yolo11m-obb-640_ncnn_model\\model.ncnn.param ncnnbin=..\\trained_models\\yolo11m-obb-640_ncnn_model\\model.ncnn.bin ncnnpy=..\\trained_models\\yolo11m-obb-640_ncnn_model\\model_ncnn.py pnnxparam=..\\trained_models\\yolo11m-obb-640_ncnn_model\\model.pnnx.param pnnxbin=..\\trained_models\\yolo11m-obb-640_ncnn_model\\model.pnnx.bin pnnxpy=..\\trained_models\\yolo11m-obb-640_ncnn_model\\model_pnnx.py pnnxonnx=..\\trained_models\\yolo11m-obb-640_ncnn_model\\model.pnnx.onnx fp16=0 device=cuda inputshape=\"[1, 3, 640, 640]\"'\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success  4.2s, saved as '..\\trained_models\\yolo11m-obb-640_ncnn_model' (79.9 MB)\n",
      "\n",
      "Export complete (7.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-640_ncnn_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-640_ncnn_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "\n",
      "🚀 Mengonversi yolo11m-obb-1280.pt...\n",
      "   🔁 Export ke format: onnx\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.5s, saved as '..\\trained_models\\yolo11m-obb-1280.onnx' (80.0 MB)\n",
      "\n",
      "Export complete (3.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-1280.onnx imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-1280.onnx imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: openvino\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2025.2.0-19140-c01cd93e24d-releases/2025/2...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  3.5s, saved as '..\\trained_models\\yolo11m-obb-1280_openvino_model\\' (80.3 MB)\n",
      "\n",
      "Export complete (4.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-1280_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-1280_openvino_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: mnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.6s, saved as '..\\trained_models\\yolo11m-obb-1280.onnx' (80.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.1...\n",
      "\u001b[34m\u001b[1mMNN:\u001b[0m export success  4.1s, saved as '..\\trained_models\\yolo11m-obb-1280.mnn' (79.9 MB)\n",
      "\n",
      "Export complete (5.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-1280.mnn imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-1280.mnn imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "   🔁 Export ke format: ncnn\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\trained_models\\yolo11m-obb-1280.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 45, 8400) (40.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  2.4s, saved as '..\\trained_models\\yolo11m-obb-1280.torchscript' (80.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250503...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running 'C:\\Users\\usudl\\anaconda3\\envs\\yolov-env\\Lib\\site-packages\\ultralytics\\pnnx.exe ..\\trained_models\\yolo11m-obb-1280.torchscript ncnnparam=..\\trained_models\\yolo11m-obb-1280_ncnn_model\\model.ncnn.param ncnnbin=..\\trained_models\\yolo11m-obb-1280_ncnn_model\\model.ncnn.bin ncnnpy=..\\trained_models\\yolo11m-obb-1280_ncnn_model\\model_ncnn.py pnnxparam=..\\trained_models\\yolo11m-obb-1280_ncnn_model\\model.pnnx.param pnnxbin=..\\trained_models\\yolo11m-obb-1280_ncnn_model\\model.pnnx.bin pnnxpy=..\\trained_models\\yolo11m-obb-1280_ncnn_model\\model_pnnx.py pnnxonnx=..\\trained_models\\yolo11m-obb-1280_ncnn_model\\model.pnnx.onnx fp16=0 device=cuda inputshape=\"[1, 3, 640, 640]\"'\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success  4.2s, saved as '..\\trained_models\\yolo11m-obb-1280_ncnn_model' (79.9 MB)\n",
      "\n",
      "Export complete (7.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\trained_models\u001b[0m\n",
      "Predict:         yolo predict task=obb model=..\\trained_models\\yolo11m-obb-1280_ncnn_model imgsz=640  \n",
      "Validate:        yolo val task=obb model=..\\trained_models\\yolo11m-obb-1280_ncnn_model imgsz=640 data=C:\\Users\\usudl\\Fitra\\OBB-YOLO\\datasets\\obb_mini_things-3/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Daftar model YOLOv11 OBB yang akan dikonversi\n",
    "models = [\n",
    "    \"yolo11n-obb-320.pt\",\n",
    "    \"yolo11n-obb-640.pt\",\n",
    "    \"yolo11n-obb-1280.pt\",\n",
    "    \"yolo11s-obb-320.pt\",\n",
    "    \"yolo11s-obb-640.pt\",\n",
    "    \"yolo11s-obb-1280.pt\",\n",
    "    \"yolo11m-obb-320.pt\",\n",
    "    \"yolo11m-obb-640.pt\",\n",
    "    \"yolo11m-obb-1280.pt\",\n",
    "]\n",
    "\n",
    "# Format target yang ingin diekspor\n",
    "export_formats = [\"onnx\", \"openvino\", \"mnn\", \"ncnn\"]  # bisa tambah: 'coreml', 'tflite', 'engine', dll\n",
    "\n",
    "# Path model dan output\n",
    "model_dir = \"../trained_models\"\n",
    "export_dir = \"../exported_models_pc\"\n",
    "\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "for model_name in models:\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"[SKIP] Model tidak ditemukan: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🚀 Mengonversi {model_name}...\")\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    for fmt in export_formats:\n",
    "        try:\n",
    "            print(f\"   🔁 Export ke format: {fmt}\")\n",
    "            model.export(format=fmt, imgsz=640, device=0)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Gagal export ke {fmt}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c188d5-55d7-47d0-8054-06eb8f72342f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Validating yolo11n-obb-320.pt at 320px...\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 135.720.2 MB/s, size: 16.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.973      0.991      0.993       0.93\n",
      "Speed: 0.6ms preprocess, 10.4ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mvalidation_outputs\\yolo11n-obb-320\u001b[0m\n",
      "\n",
      "🔎 Validating yolo11n-obb-640.pt at 640px...\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 381.6126.5 MB/s, size: 20.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.981      0.992      0.994      0.937\n",
      "Speed: 2.4ms preprocess, 18.0ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
      "Results saved to \u001b[1mvalidation_outputs\\yolo11n-obb-640\u001b[0m\n",
      "\n",
      "🔎 Validating yolo11n-obb-1280.pt at 1280px...\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 309.185.7 MB/s, size: 17.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.988      0.997      0.991      0.929\n",
      "Speed: 0.7ms preprocess, 9.5ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mvalidation_outputs\\yolo11n-obb-1280\u001b[0m\n",
      "\n",
      "🔎 Validating yolo11s-obb-320.pt at 320px...\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 300.378.8 MB/s, size: 18.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.979      0.999      0.995      0.945\n",
      "Speed: 1.9ms preprocess, 18.3ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
      "Results saved to \u001b[1mvalidation_outputs\\yolo11s-obb-320\u001b[0m\n",
      "\n",
      "🔎 Validating yolo11s-obb-640.pt at 640px...\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 296.464.9 MB/s, size: 18.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.985      0.997      0.994      0.938\n",
      "Speed: 1.8ms preprocess, 17.6ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "Results saved to \u001b[1mvalidation_outputs\\yolo11s-obb-640\u001b[0m\n",
      "\n",
      "🔎 Validating yolo11s-obb-1280.pt at 1280px...\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 317.375.3 MB/s, size: 17.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.997      0.999      0.995      0.945\n",
      "Speed: 0.6ms preprocess, 10.7ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mvalidation_outputs\\yolo11s-obb-1280\u001b[0m\n",
      "\n",
      "🔎 Validating yolo11m-obb-320.pt at 320px...\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 199.957.3 MB/s, size: 20.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.995      0.996      0.993      0.941\n",
      "Speed: 0.9ms preprocess, 17.0ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mvalidation_outputs\\yolo11m-obb-320\u001b[0m\n",
      "\n",
      "🔎 Validating yolo11m-obb-640.pt at 640px...\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 328.9112.6 MB/s, size: 18.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190          1          1      0.995      0.955\n",
      "Speed: 0.3ms preprocess, 10.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mvalidation_outputs\\yolo11m-obb-640\u001b[0m\n",
      "\n",
      "🔎 Validating yolo11m-obb-1280.pt at 1280px...\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 246.7152.6 MB/s, size: 17.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.988      0.999      0.995      0.939\n",
      "Speed: 0.6ms preprocess, 18.9ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mvalidation_outputs\\yolo11m-obb-1280\u001b[0m\n",
      "\n",
      "🔎 Validating yolo11n-obb-320.onnx at 320px...\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11n-obb-640.onnx\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11n-obb-1280.onnx\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-320.onnx\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-640.onnx\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-1280.onnx\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-320.onnx\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-640.onnx\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-1280.onnx\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11n-obb-320.openvino\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11n-obb-640.openvino\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11n-obb-1280.openvino\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-320.openvino\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-640.openvino\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-1280.openvino\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-320.openvino\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-640.openvino\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-1280.openvino\n",
      "\n",
      "🔎 Validating yolo11n-obb-320.mnn at 320px...\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11n-obb-640.mnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11n-obb-1280.mnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-320.mnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-640.mnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-1280.mnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-320.mnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-640.mnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-1280.mnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11n-obb-320.ncnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11n-obb-640.ncnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11n-obb-1280.ncnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-320.ncnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-640.ncnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11s-obb-1280.ncnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-320.ncnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-640.ncnn\n",
      "[SKIP] Model tidak ditemukan: ../trained_models\\yolo11m-obb-1280.ncnn\n",
      "\n",
      "✅ Semua hasil disimpan ke:\n",
      "- JSON: validation_outputs\\validation_benchmark.json\n",
      "- CSV : validation_outputs\\validation_benchmark.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import torch\n",
    "import platform\n",
    "import psutil\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def get_system_info():\n",
    "    return {\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"cuda_name\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n",
    "        \"cuda_memory_total_MB\": torch.cuda.get_device_properties(0).total_memory // (1024 * 1024) if torch.cuda.is_available() else None,\n",
    "        \"torch_version\": torch.__version__,\n",
    "        \"python_version\": platform.python_version(),\n",
    "        \"os\": platform.system(),\n",
    "        \"os_version\": platform.version(),\n",
    "        \"cpu\": platform.processor(),\n",
    "        \"cpu_count\": psutil.cpu_count(logical=True),\n",
    "        \"ram_total_GB\": round(psutil.virtual_memory().total / (1024 ** 3), 2),\n",
    "    }\n",
    "\n",
    "models_base = [\n",
    "    (\"yolo11n-obb\", 320),\n",
    "    (\"yolo11n-obb\", 640),\n",
    "    (\"yolo11n-obb\", 1280),\n",
    "    (\"yolo11s-obb\", 320),\n",
    "    (\"yolo11s-obb\", 640),\n",
    "    (\"yolo11s-obb\", 1280),\n",
    "    (\"yolo11m-obb\", 320),\n",
    "    (\"yolo11m-obb\", 640),\n",
    "    (\"yolo11m-obb\", 1280),\n",
    "]\n",
    "\n",
    "formats = [\"pt\", \"onnx\", \"openvino\", \"mnn\", \"ncnn\"]\n",
    "model_dir = \"../trained_models\"\n",
    "dataset_path = \"../datasets/obb_mini_things-3/data.yaml\"\n",
    "save_dir = \"validation_outputs\"\n",
    "\n",
    "benchmark_results = []\n",
    "\n",
    "for fmt in formats:\n",
    "    for base_name, size in models_base:\n",
    "        model_name = f\"{base_name}-{size}.{fmt}\"\n",
    "        model_path = os.path.join(model_dir, model_name)\n",
    "        output_name = model_name.replace(f\".{fmt}\", \"\")\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"[SKIP] Model tidak ditemukan: {model_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n🔎 Validating {model_name} at {size}px...\")\n",
    "\n",
    "        entry = {\n",
    "            \"model\": model_name,\n",
    "            \"format\": fmt,\n",
    "            \"imgsz\": size,\n",
    "            \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "            \"mAP50\": None,\n",
    "            \"mAP50-95\": None,\n",
    "            \"precision\": None,\n",
    "            \"recall\": None,\n",
    "            \"inference_time_ms\": None,\n",
    "            \"fps\": None,\n",
    "            \"note\": \"\",\n",
    "            **get_system_info()\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            if fmt == \"pt\":\n",
    "                model = YOLO(model_path)\n",
    "                results = model.val(\n",
    "                    data=dataset_path,\n",
    "                    imgsz=size,\n",
    "                    batch=1,\n",
    "                    conf=0.25,\n",
    "                    iou=0.6,\n",
    "                    device=0,\n",
    "                    project=save_dir,\n",
    "                    name=output_name,\n",
    "                    save_txt=True,\n",
    "                    save_conf=True,\n",
    "                    plots=True,\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "                entry.update({\n",
    "                    \"mAP50\": results.box.map50,\n",
    "                    \"mAP50-95\": results.box.map,\n",
    "                    \"precision\": results.box.mp,\n",
    "                    \"recall\": results.box.mr,\n",
    "                    \"inference_time_ms\": results.speed['inference'],\n",
    "                    \"fps\": 1000 / results.speed['inference'] if results.speed['inference'] else 0\n",
    "                })\n",
    "\n",
    "            else:\n",
    "                entry[\"note\"] = f\"Format {fmt.upper()} belum didukung langsung oleh Ultralytics.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            entry[\"note\"] = f\"ERROR: {str(e)}\"\n",
    "\n",
    "        benchmark_results.append(entry)\n",
    "\n",
    "# Simpan hasil ke JSON\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "json_path = os.path.join(save_dir, \"validation_benchmark.json\")\n",
    "with open(json_path, \"w\") as f_json:\n",
    "    json.dump(benchmark_results, f_json, indent=2)\n",
    "\n",
    "# Simpan hasil ke CSV\n",
    "csv_path = os.path.join(save_dir, \"validation_benchmark.csv\")\n",
    "with open(csv_path, \"w\", newline=\"\") as f_csv:\n",
    "    writer = csv.DictWriter(f_csv, fieldnames=benchmark_results[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(benchmark_results)\n",
    "\n",
    "print(f\"\\n✅ Semua hasil disimpan ke:\\n- JSON: {json_path}\\n- CSV : {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7ae16-65f7-4f98-be5c-8808d7f3a4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Validating yolo11m-obb-1280.mnn | format=mnn | size=1280 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11m-obb-1280.onnx | format=onnx | size=1280 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11m-obb-1280.pt | format=pt | size=1280 | device=cuda\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 455.1129.8 MB/s, size: 18.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.988      0.999      0.995      0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 18.9ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "\n",
      "🔎 Validating yolo11m-obb-1280.torchscript | format=torchscript | size=1280 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11m-obb-320.mnn | format=mnn | size=320 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11m-obb-320.onnx | format=onnx | size=320 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11m-obb-320.pt | format=pt | size=320 | device=cuda\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 251.366.8 MB/s, size: 17.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.995      0.996      0.993      0.941\n",
      "Speed: 0.6ms preprocess, 12.9ms inference, 0.0ms loss, 2.7ms postprocess per image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Validating yolo11m-obb-320.torchscript | format=torchscript | size=320 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11m-obb-640.mnn | format=mnn | size=640 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11m-obb-640.onnx | format=onnx | size=640 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11m-obb-640.pt | format=pt | size=640 | device=cuda\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11m-obb summary (fused): 134 layers, 20,909,323 parameters, 0 gradients, 71.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 161.917.6 MB/s, size: 15.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190          1          1      0.995      0.955\n",
      "Speed: 0.3ms preprocess, 10.7ms inference, 0.0ms loss, 2.5ms postprocess per image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Validating yolo11m-obb-640.torchscript | format=torchscript | size=640 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11n-obb-1280.mnn | format=mnn | size=1280 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11n-obb-1280.onnx | format=onnx | size=1280 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11n-obb-1280.pt | format=pt | size=1280 | device=cuda\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 355.734.4 MB/s, size: 18.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.988      0.997      0.991      0.929\n",
      "Speed: 0.5ms preprocess, 8.6ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "\n",
      "🔎 Validating yolo11n-obb-1280.torchscript | format=torchscript | size=1280 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11n-obb-320.mnn | format=mnn | size=320 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11n-obb-320.onnx | format=onnx | size=320 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11n-obb-320.pt | format=pt | size=320 | device=cuda\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 238.868.8 MB/s, size: 16.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.973      0.991      0.993       0.93\n",
      "Speed: 0.3ms preprocess, 8.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Validating yolo11n-obb-320.torchscript | format=torchscript | size=320 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11n-obb-640.mnn | format=mnn | size=640 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11n-obb-640.onnx | format=onnx | size=640 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11n-obb-640.pt | format=pt | size=640 | device=cuda\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,661,523 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 319.8107.2 MB/s, size: 17.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.981      0.992      0.994      0.937\n",
      "Speed: 0.4ms preprocess, 9.4ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "\n",
      "🔎 Validating yolo11n-obb-640.torchscript | format=torchscript | size=640 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11s-obb-1280.mnn | format=mnn | size=1280 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11s-obb-1280.onnx | format=onnx | size=1280 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11s-obb-1280.pt | format=pt | size=1280 | device=cuda\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 254.168.6 MB/s, size: 16.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.997      0.999      0.995      0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 8.8ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "\n",
      "🔎 Validating yolo11s-obb-1280.torchscript | format=torchscript | size=1280 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11s-obb-320.mnn | format=mnn | size=320 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11s-obb-320.onnx | format=onnx | size=320 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11s-obb-320.pt | format=pt | size=320 | device=cuda\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 277.378.4 MB/s, size: 18.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 121/121 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        121        190      0.979      0.999      0.995      0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.3ms preprocess, 8.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "\n",
      "🔎 Validating yolo11s-obb-320.torchscript | format=torchscript | size=320 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11s-obb-640.mnn | format=mnn | size=640 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11s-obb-640.onnx | format=onnx | size=640 | device=cuda\n",
      "\n",
      "🔎 Validating yolo11s-obb-640.pt | format=pt | size=640 | device=cuda\n",
      "Ultralytics 8.3.149  Python-3.10.16 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,714,267 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 364.4118.3 MB/s, size: 17.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usudl\\Fitra\\obb-sbc-benchmark\\datasets\\obb_mini_things-3\\valid\\labels.cache... 121 images, 0 bac\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   1%|          | 1/121 [00:00"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import torch\n",
    "import platform\n",
    "import psutil\n",
    "import re\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def get_system_info(device_override=None):\n",
    "    device = device_override if device_override else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return {\n",
    "        \"device\": device,\n",
    "        \"cuda_name\": torch.cuda.get_device_name(0) if device == \"cuda\" else None,\n",
    "        \"cuda_memory_total_MB\": torch.cuda.get_device_properties(0).total_memory // (1024 * 1024) if device == \"cuda\" else None,\n",
    "        \"torch_version\": torch.__version__,\n",
    "        \"python_version\": platform.python_version(),\n",
    "        \"os\": platform.system(),\n",
    "        \"os_version\": platform.version(),\n",
    "        \"cpu\": platform.processor(),\n",
    "        \"cpu_count\": psutil.cpu_count(logical=True),\n",
    "        \"ram_total_GB\": round(psutil.virtual_memory().total / (1024 ** 3), 2),\n",
    "    }\n",
    "\n",
    "def extract_resolution(name):\n",
    "    match = re.search(r'-(\\d{3,4})(?:\\D|$)', name)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Direktori utama\n",
    "model_dir = \"../trained_models\"\n",
    "dataset_path = \"../datasets/obb_mini_things-3/data.yaml\"\n",
    "save_dir = \"validation_outputs\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Deteksi semua file model\n",
    "model_files = sorted([f for f in os.listdir(model_dir) if f.endswith((\".pt\", \".onnx\", \".torchscript\", \".mnn\"))])\n",
    "model_dirs = sorted([f for f in os.listdir(model_dir) if os.path.isdir(os.path.join(model_dir, f)) and \"_model\" in f])\n",
    "models = model_files + model_dirs\n",
    "\n",
    "devices = []\n",
    "if torch.cuda.is_available():\n",
    "    devices.append(\"cuda\")\n",
    "devices.append(\"cpu\")  # selalu jalankan juga versi CPU\n",
    "\n",
    "benchmark_results = []\n",
    "\n",
    "for device in devices:\n",
    "    for model_name in models:\n",
    "        model_path = os.path.join(model_dir, model_name)\n",
    "        base_name = model_name.replace(\"_model\", \"\").replace(\".pt\", \"\").replace(\".onnx\", \"\").replace(\".torchscript\", \"\").replace(\".mnn\", \"\")\n",
    "\n",
    "        # Format dari ekstensi atau sufiks direktori\n",
    "        if model_name.endswith(\".pt\"):\n",
    "            fmt = \"pt\"\n",
    "        elif model_name.endswith(\".onnx\"):\n",
    "            fmt = \"onnx\"\n",
    "        elif model_name.endswith(\".mnn\"):\n",
    "            fmt = \"mnn\"\n",
    "        elif model_name.endswith(\".torchscript\"):\n",
    "            fmt = \"torchscript\"\n",
    "        elif \"openvino\" in model_name:\n",
    "            fmt = \"openvino\"\n",
    "        elif \"ncnn\" in model_name:\n",
    "            fmt = \"ncnn\"\n",
    "        else:\n",
    "            fmt = \"unknown\"\n",
    "\n",
    "        resolution = extract_resolution(base_name)\n",
    "\n",
    "        print(f\"\\n🔎 Validating {model_name} | format={fmt} | size={resolution} | device={device}\")\n",
    "\n",
    "        entry = {\n",
    "            \"model\": model_name,\n",
    "            \"format\": fmt,\n",
    "            \"imgsz\": resolution,\n",
    "            \"device\": device,\n",
    "            \"mAP50\": None,\n",
    "            \"mAP50-95\": None,\n",
    "            \"precision\": None,\n",
    "            \"recall\": None,\n",
    "            \"inference_time_ms\": None,\n",
    "            \"fps\": None,\n",
    "            \"note\": \"\",\n",
    "            **get_system_info(device_override=device)\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            if fmt == \"pt\":\n",
    "                model = YOLO(model_path)\n",
    "                results = model.val(\n",
    "                    data=dataset_path,\n",
    "                    imgsz=resolution,\n",
    "                    batch=1,\n",
    "                    conf=0.25,\n",
    "                    iou=0.6,\n",
    "                    device=0 if device == \"cuda\" else \"cpu\",\n",
    "                    project=save_dir,\n",
    "                    name=f\"{base_name}_{device}\",\n",
    "                    save_txt=True,\n",
    "                    save_conf=True,\n",
    "                    plots=False,\n",
    "                    verbose=False\n",
    "                )\n",
    "                entry.update({\n",
    "                    \"mAP50\": results.box.map50,\n",
    "                    \"mAP50-95\": results.box.map,\n",
    "                    \"precision\": results.box.mp,\n",
    "                    \"recall\": results.box.mr,\n",
    "                    \"inference_time_ms\": results.speed['inference'],\n",
    "                    \"fps\": 1000 / results.speed['inference'] if results.speed['inference'] else 0\n",
    "                })\n",
    "            else:\n",
    "                entry[\"note\"] = f\"Format {fmt.upper()} belum didukung validasi otomatis.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            entry[\"note\"] = f\"[ERROR] {str(e)}\"\n",
    "\n",
    "        benchmark_results.append(entry)\n",
    "\n",
    "# Simpan hasil ke JSON\n",
    "json_path = os.path.join(save_dir, \"validation_benchmark.json\")\n",
    "with open(json_path, \"w\") as f_json:\n",
    "    json.dump(benchmark_results, f_json, indent=2)\n",
    "\n",
    "# Simpan hasil ke CSV\n",
    "csv_path = os.path.join(save_dir, \"validation_benchmark.csv\")\n",
    "with open(csv_path, \"w\", newline=\"\") as f_csv:\n",
    "    writer = csv.DictWriter(f_csv, fieldnames=benchmark_results[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(benchmark_results)\n",
    "\n",
    "print(f\"\\n✅ Semua hasil disimpan ke:\\n- JSON: {json_path}\\n- CSV : {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a9ec6-c7d4-4b6a-932f-11c51cc778c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
